{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 代码报错\n",
    "1. neural_network/conv_net.py中，LeNet5模型的count_correct方法报错\n",
    "2. SRNet/functions.py中，ImageFunction方法中的_apply_conv方法中报错\n",
    "3. test/test_model.py中，test_diff_mlp测试时，输出对输入求梯度的时候报错\n",
    "4. test/test_net.py中，test_ModuleEQLNet测试时，求eql的表达式报错。具体错误发生在SRNet/sr_layers.py中的expr方法中\n",
    "5. train_pde.py中，pretrain_pde和train_pde方法都有问题，epoch不增加，无法正常训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abad430dc421a312"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 注意事项\n",
    "1. SRNet/parameters.py中，对于CGP模型的levels_back参数的设定，不要设置为None，否则会导致在factory.py初始化CGP模型时计算上下bounds报错\n",
    "2. SRNet/usr_model.py中，PDEEQL模型中，pde_model属性现在是EQLmodel，之后如果要进行替换的话，估计也是改这部分的代码\n",
    "3. test/test.py中，在test_grad方法测试计算梯度时，一定不能加上with torch.no_grad()，否则梯度无法计算\n",
    "4. 在执行train_find_imgpde_with_kan.sh脚本时，运行的是train_img_pde.py。args中的n_layers是pinn隐藏层的数量\n",
    "5. 在用kan替换eql的时候，由于用的是efficent-kan，其中不包含kan模型的画图和公式部分，所以在得到图像后，无法获得与之对应的偏微分方程\n",
    "6. 在用kan代替pinn时，在efficent-kan的forward操作中，有个update_grid参数，用于在训练中更新网格。如果需要设置，在usr_models.py的第865行。因为没有放在全局参数args中，所以在训练脚本中要记得同步修改；在用kan代替eql时，也可以使用网格拓展策略，在usr_models.py的第766、879行，加上update_grid参数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80f7bdeb96fd5b13"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 问题\n",
    "1. SRNet/usr_model.py中，LinearProj类中的forward操作，不知道为什么要进行维度的变换\n",
    "2. SRNet/usr_model.py中，ImageEQL模型没看懂，而且看到师兄的训练结果中还用到了\n",
    "3. SRNet/usr_model.py中，DiffCGPModel模型的参数是CGPParameter，我猜目的是使CGP可以输入偏微分项\n",
    "4. test/test_model.py中，test_diff_cgp测试通过CGP产生的表达式中，有u(x0,x1,x2)，不知道代表的是什么运算符号\n",
    "5. finetune_eql.py不知道如何运行\n",
    "6. autopum算法进行模块划分之后，代码在哪体现划分后的神经网络\n",
    "7. 将pinn和eql拆开之后，发现pinn输出的偏微分项中本来以为有三项dx，dy，dxdy，但是发现dxdy为0\n",
    "8. 论文中说设计的lenet有三层卷积，但代码中实际只有一层"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f1ba373aaa9b24b"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "lenet = torch.load(\"output/LeNet/LeNet\", map_location=torch.device('cpu'))\n",
    "for k,v in lenet.items():\n",
    "    print(k,v.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-22T09:15:45.611668Z",
     "start_time": "2024-06-22T09:15:45.596641Z"
    }
   },
   "id": "20d500a81e53083",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.0.weight torch.Size([6, 1, 5, 5])\n",
      "conv1.0.bias torch.Size([6])\n",
      "conv1.1.weight torch.Size([6])\n",
      "conv1.1.bias torch.Size([6])\n",
      "conv1.1.running_mean torch.Size([6])\n",
      "conv1.1.running_var torch.Size([6])\n",
      "conv1.1.num_batches_tracked torch.Size([])\n",
      "conv2.0.weight torch.Size([16, 6, 5, 5])\n",
      "conv2.0.bias torch.Size([16])\n",
      "conv2.1.weight torch.Size([16])\n",
      "conv2.1.bias torch.Size([16])\n",
      "conv2.1.running_mean torch.Size([16])\n",
      "conv2.1.running_var torch.Size([16])\n",
      "conv2.1.num_batches_tracked torch.Size([])\n",
      "fc.0.weight torch.Size([120, 400])\n",
      "fc.0.bias torch.Size([120])\n",
      "fc.2.weight torch.Size([84, 120])\n",
      "fc.2.bias torch.Size([84])\n",
      "fc.4.weight torch.Size([10, 84])\n",
      "fc.4.bias torch.Size([10])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "776df2993a1d7204"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
